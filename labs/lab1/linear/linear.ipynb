{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7541dec0-676e-453d-8133-034fdb0d4ec4",
   "metadata": {},
   "source": [
    "# Part 2: Linear Regression\n",
    "\n",
    "\n",
    "In this part, we will be working with a dataset scraped by [Shubham Maurya](https://www.kaggle.com/mauryashubham/linear-regression-to-predict-market-value/data), which collects facts about players in the English Premier League as of 2017. His original goal was to establish if there was a relationship between a player's popularity and his market value, as estimated by transfermrkt.com.\n",
    "\n",
    "**Your goal is to fit a model able to predict a player's market value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74827d1e-d652-424b-9d09-bf1b19a0edcb",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "The dataset contains the following information:\n",
    "| **Field**   |     **Description**      |  \n",
    "|-------------|-------------|\n",
    "| name   |  Name of the player |\n",
    "| club   |  Club of the player |\n",
    "| age    | Age of the player |\n",
    "|position| The usual position on the pitch\n",
    "|position_cat| 1 for attackers, 2 for midfielders, 3 for defenders, 4 for goalkeepers|\n",
    "|market_value| As on transfermrkt.com on July 20th, 2017|\n",
    "|page_views| Average daily Wikipedia page views from September 1, 2016 to May 1, 2017|\n",
    "|fpl_value| Value in Fantasy Premier League as on July 20th, 2017|\n",
    "|fpl_sel| % of FPL players who have selected that player in their team|\n",
    "|fpl_points| FPL points accumulated over the previous season|\n",
    "|region| 1 for England, 2 for EU, 3 for Americas, 4 for Rest of World|\n",
    "|nationality| Player's nationality|\n",
    "|new_foreign| Whether a new signing from a different league, for 2017/18 (till 20th July)|\n",
    "|age_cat| a categorical version of the Age feature|\n",
    "|club_id| a numerical version of the Club feature|\n",
    "|big_club| Whether one of the Top 6 clubs|\n",
    "|new_signing| Whether a new signing for 2017/18 (till 20th July)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7487f9-e685-4b2e-a215-7e6eabdec94a",
   "metadata": {},
   "source": [
    "## Exercise 1: Exploring the data\n",
    "The first step you need to do is to explore your data.\n",
    "\n",
    "We will start wil the necessary imports. In this exercise, we will be working with the library `pandas`. If you are not familiar with it, it is recommended that you follow the introductory exercises that can be found in the course's github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a7653-e8ac-4644-8421-cfe8bc2a3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16bb16-66ed-421c-a97a-d949b94aef29",
   "metadata": {},
   "source": [
    "We will now proceed to read the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7b303c-61f7-4a0d-babc-dc830b6251b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "league_df = pd.read_csv('data/football_data.csv') #Reads a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523a70e-af15-4766-9d65-d01758ca9146",
   "metadata": {},
   "source": [
    "### Task 1.1: Using pandas for data exploration\n",
    "Use the method `name_dataframe.head(N)` (N is the number of entries) to look at the first instances of the dataframe. \n",
    "\n",
    "Then, use the method `name_dataframe.describe(include='all')` to generate descriptive statistics that summarize each field of the dataframe. \n",
    "\n",
    "Finally, print the result of `name_dataframe.dtypes`, in this way you print out the data types associated to each of the fields in the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c1a939-e6fc-410b-8110-90a844ba6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code for head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515dd667-c6a2-44b3-9faf-6110885f4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code for describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f011b3-717d-4b64-87f2-9fc5eb7f8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code for d_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a406237-ec01-4643-83ce-53c2b740f809",
   "metadata": {},
   "source": [
    "### Question set 1.1: About the data\n",
    "1. What is the name of the appearing in the 7th record of the dataset?\n",
    "2. What is the mean age in the English Premier League (in 2017)? \n",
    "3. What fields store a continuous value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0e869-6e8e-49f9-84c8-8813aa2fb8fa",
   "metadata": {},
   "source": [
    "Your answers here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ab84d-f6d6-4ede-8b61-7b8fce77030a",
   "metadata": {},
   "source": [
    "## Exercise 2: Data splits, data preparation and training\n",
    "Before starting the training procedure, we need to split the data into the training, validation and test sets.\n",
    "\n",
    "In this exercise, the data will be already given split for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd9aea-3abc-4616-b36d-916f012a7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the splits\n",
    "df_train = pd.read_csv('data/league_train.csv')\n",
    "df_val = pd.read_csv('data/league_val.csv')\n",
    "df_test = pd.read_csv('data/league_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef915478-b205-467d-a113-7546ce29d685",
   "metadata": {},
   "source": [
    "Alternatively, for the type of data used in this exercise, the library `scikit-learn` contains the function `train_test_split` that allows to automatically split the data.\n",
    "\n",
    "### Question set 2.1 Train_test_split\n",
    "Look at the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) of the `train_test_split` function:\n",
    "1. What parameters it receives as input? Provide examples illustrating.\n",
    "2. What is the role of the parameter shuffle?\n",
    "3. What is the role of the parameter test_size?\n",
    "4. The function does not generate a validation set. What would you do to obtain the desired data splits (train, validation and test)? Answer using pseudo-code (Bonus: Write the code for it so that it can run using some dummy generated data). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a70d65c-4813-4e3f-b155-620a2201fa0f",
   "metadata": {},
   "source": [
    "Your answers here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107b65f-b24f-498a-9853-ea40fa932d88",
   "metadata": {},
   "source": [
    "The dataset contains a lot of features that can be used to build the model. We will start by using `age, fpl_value, big_club` and `page_views`.\n",
    "\n",
    "$$\\hat{y} = w_0 + w_1 x_{age} + w_2 x_{fplavalue} + w_3 x_{bigclub} + w_4(x_{pageviews})^{1/2}$$\n",
    "\n",
    "Before training the model, we need to prepare the data so that it can be used for training, validation and testing. The following steps need to be executed to prepare the data:\n",
    "\n",
    "1. Apply the np.sqrt( ) on the values of page_views\n",
    "2. Transform our variable in numpy array np.array(variable)\n",
    "3. Add a columns of ones to the matrix $\\mathbf{X}$  so it can handle the parameter $w_0$.\n",
    "\n",
    "### Task 2.1 Prepare data\n",
    "Complete the function `prepare_data(DataFrame)` where indicated so that all the steps listed above are performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29378bc9-0709-476f-a79f-c8b9c0735794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def prepare_data(df):\n",
    "    '''\n",
    "        INPUT :\n",
    "        - df : a pandas DataFrame\n",
    "\n",
    "         OUTPUT :\n",
    "        - variable_array : The processed array\n",
    "    ''' \n",
    "    #We obtain a copy of the relevalnt fields from the DataFrame. This avoids modifying the dataframe directly. Instead, we work in a copy. Notice that we are not copying pageviews field\n",
    "    variable = df[['age', 'fpl_value', 'big_club']].copy()\n",
    "    \n",
    "    #Step 1.  Apply the np.sqrt( ) on the values of page_views\n",
    "    variable['sqrt_page_views'] = # YOUR CODE HERE\n",
    "    \n",
    "    # Step 2. Transform our variable in numpy array np.array(variable)\n",
    "    variable_array = #YOUR CODE HERE\n",
    "    \n",
    "    # Step 3. Add a columns of ones to the matrix ùêó so it can handle the parameter ùë§0.\n",
    "    # For this purpose we will use the function PolynomialFeatures from scikit-learn\n",
    "    variable_array = PolynomialFeatures(1).fit_transform(variable_array)\n",
    "\n",
    "    return variable_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c08aee-c052-47d7-b49b-c7a1f1b1ffd8",
   "metadata": {},
   "source": [
    "### Question set 2.2 PolynomialFeatures function\n",
    "Investigate the role of the [Polynomial features function](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) from scikit-learn. \n",
    "1. Why did the order of the polynomial was set to one in the prepare_data function? \n",
    "2. Given two features $x_1, x_2$, write down the expression that you would obtain by using the function by setting `degree=2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9509668-b80f-4fcf-bf8a-cd2f7d1b362f",
   "metadata": {},
   "source": [
    "Your answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8442bf4d-c6bf-4344-add4-156b023d1f28",
   "metadata": {},
   "source": [
    "Now, we execute the function to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba392a-3eb8-4101-b167-c0d872c9741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We copy the output label\n",
    "output_df_train=df_train['market_value'].copy()\n",
    "#We remove the output label from X\n",
    "input_df_train=df_train.drop(['market_value'],axis=1)\n",
    "\n",
    "#process is repeated for test and validation\n",
    "output_df_val=df_val['market_value'].copy()\n",
    "input_df_val=df_val.drop(['market_value'],axis=1)\n",
    "\n",
    "output_df_test=df_test['market_value'].copy()\n",
    "input_df_test=df_test.drop(['market_value'],axis=1)\n",
    "\n",
    "#We call prepare_data\n",
    "X_train = prepare_data(input_df_train)\n",
    "X_val = prepare_data(input_df_val)\n",
    "X_test = prepare_data(input_df_test)\n",
    "y_train = np.array(output_df_train)\n",
    "y_val = np.array(output_df_val)\n",
    "y_test = np.array(output_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8651c90-cf25-4808-aa42-281298c56503",
   "metadata": {},
   "source": [
    "We will now proceed to train our first model. In this case, we will use a \"home made\" implementation of linear regression. When dealing with more complex (and real) applications it is best to use the implementation that can be found in scikit-learn. \n",
    "\n",
    "We will define a class called my_linear_regression with four methods:\n",
    "1. `__init__(self)` : Constructor for the object to assign the object its properties\n",
    "2. `fit(self, X, y)` : Learning step of linear regression.\n",
    "3. `predict(self, X)` : predicts new labels $\\hat{y}$ given an input X\n",
    "4. `MSE(self,y_pred, y_test)` : Estimates the mean sum of squared errors between a set of predictions and the ground truth. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1026b99-7939-43ad-bbd3-c9ff992cfe4b",
   "metadata": {},
   "source": [
    "### Task 2.2 Mean sum of squared errors\n",
    "Implement the MSE function in the class below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e5e4a-f643-4420-9e4b-3ebc148a35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_linear_regression:\n",
    "    def __init__(self) : # initialize constructor for the object to assign the object its properties\n",
    "        self.X_train = []\n",
    "        self.y_train = []\n",
    "        self.weights = []\n",
    "        \n",
    "    def fit(self, X, y) :\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.weights = np.linalg.solve(X.T@X,X.T@y)\n",
    "    \n",
    "    def predict(self,x_test) : # method of the object that can be used\n",
    "        self.y_hat=np.sum(x_test*self.weights,axis=1)\n",
    "        \n",
    "        return self.y_hat\n",
    "    \n",
    "    def MSE(self,y_pred, y_test) :\n",
    "        #YOUR CODE HERE\n",
    "        \n",
    "        #YOUR CODE ENDS HERE\n",
    "        return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5120e9aa-0d4f-4097-b178-c6efdd2f8244",
   "metadata": {},
   "source": [
    "Now we can train our first model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea396b-e75b-40f4-8980-06510d719f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1=my_linear_regression()\n",
    "model_1.fit(X_train,y_train)\n",
    "\n",
    "print(f'The learned model has parameters:\\n{model_1.weights}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf4b917-1d14-4d15-be62-6db8c010c9e6",
   "metadata": {},
   "source": [
    "### Question set 2.3: Interpreting the weights\n",
    "The estimated weights $\\mathbf{w}$ (excluding $w_0$) are associated to 'age', 'fpl_value', 'big_club' and 'page_views' (squared root), in that order. \n",
    "1. How do you interpret the values of each of these parameters? Based on this information, what can you say about the effect in a player's market value of his: age? number of page views? fpl value?\n",
    "2. Which of these features seems to have the largest effect on a player's value? \n",
    "3. How do you interpret the value obtained for $w_0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa4974-67be-48c0-b88f-66e50234bf22",
   "metadata": {},
   "source": [
    "## Exercise 3: Adding categorical features\n",
    "It is well known that the position where a football player plays has an impact in his market value. Midfielders and stikers tend to be more expensive. Your goal now is to include this information in the model.\n",
    "\n",
    "As seen from the description, the player position is encoded as a numeric variable (1, 2, 3, 4). However, they represent categories and not values on their own. Categorical variables are commonly encoded under a scheme denoted 1-of-K encoding. This allows to convert a variable representing K different categories into K different binary values. Example:\n",
    "\n",
    "| **attacker**   |  **midfielder**      |  **defender** | **goalkeeper** |\n",
    "|-------------|-------------|-------------|-------------|\n",
    "| 1 | 0 | 0 | 0|\n",
    "| 0 | 1 | 0 | 0 |\n",
    "| 0 | 0 | 1 | 0 |\n",
    "| 0 | 0 | 0 | 1 | \n",
    "\n",
    "### Question 3.1: Adding the position to the model\n",
    "Write down the expression of the model if you consider the position of the player using 1-of-K encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527293ec-10be-465d-a93f-8d90d0e09fc9",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ec7a6-05f7-4d77-a219-3ae9b4f4586d",
   "metadata": {},
   "source": [
    "### Task 3.1 Preparing data with position features\n",
    "We need to modify the data preparation function so that it now includes the categorical features. For this matter, we have implemented the function `prepare_data_with_position(df)`. It contains the same functionality as the function `prepare_data(df)` and it adds the generation of the 1-of-K encoding. \n",
    "\n",
    "Complete the missing code in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4e35c-44eb-423a-87fe-bf56f768e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_with_position(df):\n",
    "    variable = df[['age', 'fpl_value', 'big_club']].copy()\n",
    "    variable['sqrt_page_views'] =  #YOUR CODE HERE\n",
    "\n",
    "    variable=variable.join(pd.get_dummies(df.position_cat, prefix='pos')) # get_dummies to create 1-of-K encoding, join to add the new columns\n",
    "    variable_array = # YOUR CODE HERE\n",
    "    variable_array = PolynomialFeatures(1).fit_transform(variable_array)\n",
    "    \n",
    "    return variable_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497107d8-4e45-4a83-99b5-bf944f018f63",
   "metadata": {},
   "source": [
    "### Question 3.2 The get_dummies function\n",
    "Explain what the following line of code is doing:\n",
    "\n",
    "`variable=variable.join(pd.get_dummies(df.position_cat, prefix='pos'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa07407-83c6-41e4-a133-3fef4d3ad9df",
   "metadata": {},
   "source": [
    "### Task 3.2 Train the new model\n",
    "Your task now is to train the new model. For this you will need to execute the following steps: \n",
    "1. Prepare all your data (train, validation and testing). \n",
    "2. Create a new `my_linear_regression` object and store it in a variable named `model_2`\n",
    "3. Run the learning process\n",
    "4. For inspection purposes, print out the obtained weights.\n",
    "\n",
    "**Important:** While preparing the data, make sure you do not override the previous data used for model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a227776-fe52-4a4a-8a2b-52e3bbe65374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ed5c8-116d-43fa-b522-9320fc49a791",
   "metadata": {},
   "source": [
    "### Question 3.3 Value of the position\n",
    "Based on the obtained weights, does it seem as if the position of the player has an important role in his market value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae4a64-4ead-4822-8553-e42b0faad380",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0f635-fd20-470f-9c71-404c09ceb068",
   "metadata": {},
   "source": [
    "## Exercise 4: Choosing a model\n",
    "We will now use the validation set to choose between the two models we have built so far. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3850c100-9372-4d42-879d-cdfd633171a9",
   "metadata": {},
   "source": [
    "### Task 4.1 MSE estimation\n",
    "Using the validation data, estimate the MSE for each of the two models that you have built so far. For this you will need to: \n",
    "1. Predict labels for the validation set using each of the trained models.\n",
    "2. Call the MSE function from any of the two models (it is equivalent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a22cf-fa48-40e7-b11f-04f7a05d0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------YOUR CODE HERE ------------\n",
    "\n",
    "#------------ YOUR CODE ENDS HERE ---------\n",
    "\n",
    "print(f'MSE model 1 :\\n{mse_1}\\n')\n",
    "print(f'MSE model 2 :\\n{mse_2}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455b1f0-95d9-401b-921b-6fb18bb495aa",
   "metadata": {},
   "source": [
    "### Question set 4.1 Analysis\n",
    "1. Based on the obtained results, which model would you choose?\n",
    "2. Is the position feature useful to improve the model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42b5ff-f85e-4a70-8cae-606f2d675742",
   "metadata": {},
   "source": [
    "## Exercise 5: Model testing\n",
    "Use the test dataset to evaluate the generalization capabilities of the **model you chose** in the previous step. For this you need to:\n",
    "1. Predict the labels of the test set\n",
    "2. Estimate the MSE. Please note that other metrics, such as the RSS, could be used as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753114c5-80aa-4294-b4e2-10f4291a7fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------YOUR CODE HERE ------------\n",
    "\n",
    "#------------ YOUR CODE ENDS HERE ---------\n",
    "\n",
    "print(f'MSE test:\\n{mse}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9df6f-f37b-4204-89fe-4b140e983d16",
   "metadata": {},
   "source": [
    "### Question 5.1 Analysis\n",
    "Based on the previous result, what can you say about your model? Do you consider it makes sufficiently accurate predictions? Feel free to implement other metrics if you consider you need further information. Examples: RSS, Root Mean Squared Error or Mean Absolute Error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75323326-1b88-466e-b97f-e0346e5b8742",
   "metadata": {},
   "source": [
    "Your answer here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721d943-d9b0-4816-8867-ddcae7544da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
